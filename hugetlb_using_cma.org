* Dynamic allocation of 1 GB hugepages

  x86_64 allows to map the physical memory in 1 GB chunks, which can
  drastically reduce the amount of TLB misses and give up to 3-5%
  performance gain for certain workloads.

  Experiments with HHVM showed that 1 GB hugepages provide some performance gain 
  over 2 MB pages and 4k pages. 

  1 GB hugepages were previously used on twi (together with 2 MB pages).
  As we're moving towards a shared pull of hosts (twshared), using 1 GB
  hugepages which requires a semi-manual boot-time reservation becomes harder
  and harder. So it's a good time to enhance something on the kernel side
  and allow to allocate them dynamically.

* Allocation challenges and memory fragmentation
  The main problem with 1GB hugepages is how hard it is to get a contiguous aligned
  1 GB chunk of free physical memory. With uptime the memory is getting fragmented fast 
  by different kinds of unmovable and unreclaimable objects: slabs, page tables, 
  various other kernel objects. Unlike userspace pages, which are  accessed through 
  the virtual mapping, kernel memory is mapped directly. So it's not  possible to unmap 
  a page, move the data to a different location and map it back at the same virtual address. 
  More precisely, it can be done in a theory, but will complicate the already complicated 
  memory management subsystem a lot.

  So currently 1GB hugepages can be only allocated on boot (using a kernel boot argument)
  or immediately after the start of the system, when the memory is almost entirely empty.

* Using the CMA allocator
  CMA (Contiguous Memory Allocator) is a part of Linux memory management subsystem
  responsible for allocating large block of physically contiguously memory. It has been
  developed mostly for using by different device drivers, which might need a chunk of
  memory to share with a device. But there are other use cases too:
  for instance, it's used by kvm on powerpc in order to allocate space for guest system
  pagetable. More details on CMA can be found in this good, but a bit out-dated article:
  https://lwn.net/Articles/486301/ The idea of using it for hugetlb allocations looks
  obvious, however it looks like nobody tried it yet (or at least didn't public any patches).

  So we've decided to try using CMA to allocate 1GB hugepages dynamically. It can't be done
  straight away, because the CMA allocator uses some pre-configured memory areas, which
  are allocated on boot. None of the existing areas are big enough for our purposes.
  The solution was to add a kernel boot argument, which allows to spawn an additional 
  cma area of a given size. If it needs to spawn an area on boot, why it's better than
  just pre-allocating 1GB hugepages? Simply because the memory can be used by others 
  even if nobody is using it to allocate hugepages. It can be used for the majority
  of purposes like pagecache and anonymous userspace memory, but can't be used for
  putting unmovable kernel objects. If the area is relatively small, it shouldn't play
  a big role: the kernel data doesn't usually consume a half of total memory.

  The first attempt looked a bit too optimistic: it was possible to allocate 
  1 GB hugepages dynamically with a good success rate. But then several issues 
  were discovered. They were mutually excluding to some extent, so the result 
  looked like as working:
    1) cma area was barely used even under moderate memory pressure
    2) once it started being used, 1 GB allocations were not successful in a good number of cases

  Rik and I spent a lot of time investigating and fixing various aspects of this problem:
  we've ended up adding/fixing THP splitting, ext4 superblock readahead code, btrfs
  page migration code* and the page allocator code. Our work has been well accepted
  by the community and almost all these patches are upstream or on the way to the upstream 
  kernel. 5.2-fbk12 will contain them all too.

  * big thanks to Chris Mason and Josef Bacik for a lot of help here!

* What's next
  The hostprofile team is working hard to add support for 1GB hugepages on twshared.
  This will allow to use 1GB hugepages effectively on twshared. The support of 
  the dynamic allocation from the kernel will help to avoid costly reboots.

  As we'll roll-out 5.2-fbk12 and newer kernel and enable the dynamic allocation
  of 1 GB hugepages, we expect to find new problems with page migration. Migrating
  a page is not that easy and there are many corner cases which can reduce the success 
  rate. We're planning to find and resolve these cases one-by-one. A good thing about
  this work is that it's not only about 1 GB hugepages: it makes the memory 
  defragmentation more reliable and efficient in general, which can provide multiple
  performance benefits. Also, dynamic allocation of large contiguous areas can make
  a big difference for GPUs.
